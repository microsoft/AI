{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test deployed web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we test the latency of the deployed web application by sending a number of duplicate questions as asychronous requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import urllib.request\n",
    "from timeit import default_timer\n",
    "\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from azureml.core.webservice import AksWebservice\n",
    "from azureml.core.workspace import Workspace\n",
    "from dotenv import get_key, find_dotenv\n",
    "from tqdm import tqdm\n",
    "from utilities import text_to_json, get_auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aiohttp.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(auth=get_auth(env_path))\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's retrive the web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aks_service_name = get_key(env_path, 'aks_service_name')\n",
    "aks_service = AksWebservice(ws, name=aks_service_name)\n",
    "aks_service.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our deployed service with 100 calls. We will only have 4 requests concurrently at any time. Feel free to try different values and see how the service responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_REQUESTS = 100  # Total number of requests\n",
    "CONCURRENT_REQUESTS = 4   # Number of requests at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring URL and API key of the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_url = aks_service.scoring_uri\n",
    "api_key = aks_service.get_keys()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes_test_path = './data_folder/dupes_test.tsv'\n",
    "dupes_test = pd.read_csv(dupes_test_path, sep='\\t', encoding='latin1')\n",
    "dupes_to_score = dupes_test.iloc[:NUMBER_OF_REQUESTS,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [[scoring_url, jsontext] for jsontext in dupes_to_score.apply(text_to_json)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(result):\n",
    "    return json.loads(result.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(url, session, data, headers):\n",
    "    start_time = default_timer()\n",
    "    async with session.request(\"post\", url, data=data, headers=headers) as response:\n",
    "        resp = await response.read()\n",
    "        elapsed = default_timer() - start_time\n",
    "        return resp, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def bound_fetch(sem, url, session, data, headers):\n",
    "    # Getter function with semaphore.\n",
    "    async with sem:\n",
    "        return await fetch(url, session, data, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def await_with_progress(coros):\n",
    "    results = []\n",
    "    for f in tqdm(asyncio.as_completed(coros), total=len(coros)):\n",
    "        result = await f\n",
    "        results.append((decode(result[0]), result[1]))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run(url_list, num_concurrent=CONCURRENT_REQUESTS):\n",
    "    headers = {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"Authorization\": (\"Bearer \" + api_key),\n",
    "    }\n",
    "    tasks = []\n",
    "    # create instance of Semaphore\n",
    "    sem = asyncio.Semaphore(num_concurrent)\n",
    "\n",
    "    # Create client session that will ensure we dont open new connection\n",
    "    # per each request.\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for url, data in url_list:\n",
    "            # pass Semaphore and session to every POST request\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, url, session, data, headers))\n",
    "            tasks.append(task)\n",
    "        return await await_with_progress(tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we run the 100 requests against our deployed service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "start_time = default_timer()\n",
    "complete_responses = loop.run_until_complete(\n",
    "    asyncio.ensure_future(run(url_list, num_concurrent=CONCURRENT_REQUESTS))\n",
    ")\n",
    "elapsed = default_timer() - start_time\n",
    "print(\"Total Elapsed {}\".format(elapsed))\n",
    "print(\"Avg time taken {0:4.2f} ms\".format(1000 * elapsed / len(url_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example response\n",
    "complete_responses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the number of original questions to count the succesful responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_questions = len(eval(complete_responses[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_succesful = [len(eval(i[0])) for i in complete_responses].count(no_questions)\n",
    "print(\"Succesful {} out of {}\".format(num_succesful, len(url_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will explore the real-time scoring in an [iPyWidget app](07_RealTimeScoring.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLAKSDeployAML]",
   "language": "python",
   "name": "conda-env-MLAKSDeployAML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
